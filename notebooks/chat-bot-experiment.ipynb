{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import Docx2txtLoader, TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory, ConversationBufferMemory, ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import ValidationError\n",
    "\n",
    "from src.schemas import Ring\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../data')\n",
    "customization_filepath = DATA_DIR / 'customization.md'\n",
    "faq_filepath = DATA_DIR / 'FAQ.md'\n",
    "\n",
    "customization_loader = TextLoader(file_path=customization_filepath, encoding='utf-8')\n",
    "faq_loader = TextLoader(file_path=faq_filepath, encoding='utf-8')\n",
    "\n",
    "customization_documents = customization_loader.load()\n",
    "faq_documents = faq_loader.load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daryna/miniconda3/envs/ring-customizer/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/home/daryna/miniconda3/envs/ring-customizer/lib/python3.11/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "embedding_model = OpenAIEmbeddings()\n",
    "index = VectorstoreIndexCreator(\n",
    "    embedding=embedding_model,\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([customization_loader, faq_loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We offer American sizes from 4 to 13, including half sizes. Here are the available sizes:\\n\\n- 4\\n- 4.5\\n- 5\\n- 5.5\\n- 6\\n- 6.5\\n- 7\\n- 7.5\\n- 8\\n- 8.5\\n- 9\\n- 9.5\\n- 10\\n- 10.5\\n- 11\\n- 11.5\\n- 12\\n- 12.5\\n- 13'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query =\"Please list all possible sizes for the ring\"\n",
    "response = index.query(query, llm=llm)\n",
    "display(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If your ring has a diameter of 15.1mm, your American ring size would be approximately 4.5.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query =\"What is my American size of the ring, if it is 15.1mm in diameter?\"\n",
    "response = index.query(query, llm=llm)\n",
    "display(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=10, ai_prefix='AI', human_prefix='Customer')\n",
    "with open(customization_filepath, 'r') as f:\n",
    "    customization_text = f.read()\n",
    "\n",
    "\n",
    "template = f\"\"\"\n",
    "AI is interacting with the Customer to collect ring customization preferences.\n",
    "AI is listing  all the possible customizations for the ring in the first message to the Customer, which are:\n",
    "{customization_text}\n",
    "And asks the Customer to specify selected customizations. If the Customer missed something the AI\n",
    "asks about the missing customization. The AI is not making the decisions instead of customer!\n",
    "\"\"\"\n",
    "template += \"\"\"\n",
    "Then the AI collects the Customer's answers and fill up the output JSON with the following fields:\n",
    "Material\n",
    "Style\n",
    "Surface\n",
    "Size\n",
    "Ring width\n",
    "Engraving\n",
    "\n",
    "In the Customer does not want engraving set the field Engraving to null.\n",
    "After all customizations are collected AI asks the Customer if everything is correct. In case of \n",
    "confirmation from the Customer is received the AI should output JSON (and only JSON) above with field Verified: true \n",
    "added to. In case of verified false ask the Customer about correctness again.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Customer: {input}\n",
    "AI:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=['history', 'input'], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    prompt=prompt_template,\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "def attemp_ring_parsing(response) -> Optional[Ring]:\n",
    "    try:\n",
    "        ring_dict = json.loads(response)\n",
    "        try:\n",
    "            if not ring_dict.get('Verified', None):\n",
    "                not_verified_input = \"\"\"\n",
    "Field Verified is missing or set to false. \n",
    "The AI should ask the Customer about the correctness of the ring customizations, \n",
    "showing the current customizations.\n",
    "                \"\"\"\n",
    "                print('Admin:', not_verified_input)\n",
    "                response = conversation.predict(\n",
    "                    input=not_verified_input\n",
    "                )\n",
    "                print('AI:', response)\n",
    "            else:\n",
    "                ring = Ring(**{k.lower().replace(' ', '_'): v for k, v in ring_dict.items()})\n",
    "                return ring\n",
    "        except ValidationError as e:\n",
    "            fix_input = f\"\"\"\n",
    "When parsing the output the following error happened: {e}.\n",
    "Continue the conversation, explain and ask the Customer about the issue and clarify\n",
    "the order, to fix the issue. AI does not attempt to change the customizations instead of the Customer,\n",
    "but is being helpful in suggesting what can be changed for the order to be accepted.\n",
    "After the issues above are solved AI asks the user about correctness of the selected customizations \n",
    "one more time.\n",
    "\"\"\"\n",
    "            print('Admin:', fix_input)\n",
    "            response = conversation.predict(\n",
    "                input=fix_input\n",
    "            )\n",
    "            print('AI:', response)\n",
    "\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "def handle_conversation(conversation):\n",
    "    manual_input = input()\n",
    "    print('Customer:', manual_input)\n",
    "    response = conversation.predict(\n",
    "        input=manual_input\n",
    "    )\n",
    "    print('AI:', response)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer: hello\n",
      "AI: Hello! I'm here to help you customize your ring. Here are the possible customizations:\n",
      "Material:\n",
      "- Yellow Gold\n",
      "- White Gold\n",
      "- Platinum\n",
      "- Sterling Silver\n",
      "- Titanium\n",
      "\n",
      "Style:\n",
      "- Classic\n",
      "- Modern\n",
      "- Vintage\n",
      "- Bohemian\n",
      "\n",
      "Surface:\n",
      "- Polished\n",
      "- Matte\n",
      "- Hammered\n",
      "- Brushed\n",
      "\n",
      "Size: From 4 to 13\n",
      "Ring Width: From 1mm to 8mm\n",
      "Engraving: Up to 20 characters or empty\n",
      "\n",
      "Please specify your selected customizations. If you missed something, feel free to let me know.\n",
      "Customer: gold, classic, polished, size 5.2, 1.5mm\n",
      "AI: Great choices! Just one more thing, would you like to add any engraving to your ring? If so, please provide the text (up to 20 characters), or if not, just let me know.\n",
      "Customer: No engraving\n",
      "AI: Perfect! Here is the summary of your customizations:\n",
      "{\n",
      "  \"Material\": \"Yellow Gold\",\n",
      "  \"Style\": \"Classic\",\n",
      "  \"Surface\": \"Polished\",\n",
      "  \"Size\": 5.2,\n",
      "  \"Ring Width\": \"1.5mm\",\n",
      "  \"Engraving\": null,\n",
      "  \"Verified\": false\n",
      "}\n",
      "\n",
      "Is everything correct? If so, please confirm. If not, feel free to make any changes.\n",
      "Customer: correct\n",
      "AI: {\n",
      "  \"Material\": \"Yellow Gold\",\n",
      "  \"Style\": \"Classic\",\n",
      "  \"Surface\": \"Polished\",\n",
      "  \"Size\": 5.2,\n",
      "  \"Ring Width\": \"1.5mm\",\n",
      "  \"Engraving\": null,\n",
      "  \"Verified\": true\n",
      "}\n",
      "Admin: \n",
      "When parsing the output the following error happened: 1 validation error for Ring\n",
      "size\n",
      "  Input should be a multiple of 0.5 [type=multiple_of, input_value=5.2, input_type=float]\n",
      "    For further information visit https://errors.pydantic.dev/2.7/v/multiple_of.\n",
      "Continue the conversation, explain and ask the Customer about the issue and clarify\n",
      "the order, to fix the issue. AI does not attempt to change the customizations instead of the Customer,\n",
      "but is being helpful in suggesting what can be changed for the order to be accepted.\n",
      "After the issues above are solved AI asks the user about correctness of the order one more time.\n",
      "\n",
      "AI: I apologize for the error in the order. The size you selected, 5.2, should be a multiple of 0.5. Would you like to change the size to 5.5 or any other multiple of 0.5 to proceed with the order? Please let me know your preference so we can finalize the customization. Thank you for your understanding.\n",
      "Customer: what is wrong\n",
      "AI: The size you selected, 5.2, should be a multiple of 0.5 for the order to be processed correctly. Would you like to change the size to 5.5 or any other multiple of 0.5? Please let me know your preference so we can finalize the customization. Thank you for your understanding.\n",
      "Customer: 5.5\n",
      "AI: Great choice! Here is the updated summary of your customizations:\n",
      "{\n",
      "  \"Material\": \"Yellow Gold\",\n",
      "  \"Style\": \"Classic\",\n",
      "  \"Surface\": \"Polished\",\n",
      "  \"Size\": 5.5,\n",
      "  \"Ring Width\": \"1.5mm\",\n",
      "  \"Engraving\": null,\n",
      "  \"Verified\": false\n",
      "}\n",
      "\n",
      "Is everything correct now with the size changed to 5.5? If so, please confirm. If not, feel free to make any other changes.\n",
      "Customer: sorry, repeat please\n",
      "AI: AI: Of course! Here is the updated summary of your customizations with the size changed to 5.5:\n",
      "{\n",
      "  \"Material\": \"Yellow Gold\",\n",
      "  \"Style\": \"Classic\",\n",
      "  \"Surface\": \"Polished\",\n",
      "  \"Size\": 5.5,\n",
      "  \"Ring Width\": \"1.5mm\",\n",
      "  \"Engraving\": null,\n",
      "  \"Verified\": false\n",
      "}\n",
      "\n",
      "Is everything correct now with the size changed to 5.5? If so, please confirm. If not, feel free to make any other changes. Let me know if you need any further assistance.\n",
      "Customer: seems to be correct\n",
      "AI: {\n",
      "  \"Material\": \"Yellow Gold\",\n",
      "  \"Style\": \"Classic\",\n",
      "  \"Surface\": \"Polished\",\n",
      "  \"Size\": 5.5,\n",
      "  \"Ring Width\": \"1.5mm\",\n",
      "  \"Engraving\": null,\n",
      "  \"Verified\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    manual_input = input()\n",
    "    print('Customer:', manual_input)\n",
    "    response = conversation.predict(\n",
    "        input=manual_input\n",
    "    )\n",
    "    print('AI:', response)\n",
    "    if ring := attemp_ring_parsing(response):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ring(material='Yellow Gold', style='Classic', surface='Polished', size=5.5, ring_width=1.5, engraving=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ring-customizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
