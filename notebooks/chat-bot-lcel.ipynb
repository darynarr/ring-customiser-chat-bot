{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daryna/pet_projects/ring-customiser-chat-bot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daryna/miniconda3/envs/ring-customizer/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from enum import Enum\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import EnumOutputParser\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "from src.schemas import Ring, SupportRequest\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 867, which is longer than the specified 200\n",
      "Created a chunk of size 213, which is longer than the specified 200\n",
      "Created a chunk of size 248, which is longer than the specified 200\n",
      "/home/daryna/miniconda3/envs/ring-customizer/lib/python3.11/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path('data')\n",
    "customization_filepath = DATA_DIR / 'customization.md'\n",
    "faq_filepath = DATA_DIR / 'FAQ.md'\n",
    "\n",
    "customization_loader = TextLoader(file_path=customization_filepath, encoding='utf-8')\n",
    "faq_loader = TextLoader(file_path=faq_filepath, encoding='utf-8')\n",
    "\n",
    "customization_documents = customization_loader.load()\n",
    "faq_documents = faq_loader.load();\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "customization_docs = text_splitter.split_documents(customization_documents)\n",
    "faq_docs = text_splitter.split_documents(faq_documents)\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore_customizations = DocArrayInMemorySearch.from_documents(\n",
    "    customization_docs, \n",
    "    embedding_model\n",
    ")\n",
    "vectorstore_faq = DocArrayInMemorySearch.from_documents(\n",
    "    faq_docs, \n",
    "    embedding_model\n",
    ")\n",
    "\n",
    "retriever_customizations = vectorstore_customizations.as_retriever(search_kwargs={'k': 2})\n",
    "retriever_faq = vectorstore_faq.as_retriever(search_kwargs={'k': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval with history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(prompt_str, include_history = True):\n",
    "    messages = [(\"system\", prompt_str)]\n",
    "    if include_history:\n",
    "        messages.append(MessagesPlaceholder(variable_name=\"history\"))\n",
    "    messages.append((\"human\", \"{input}\"))\n",
    "\n",
    "    return ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()\n",
    "prompt_str = \"\"\"Answer the question below using the context:\n",
    "\n",
    "Context:\n",
    "{context_customizations}\n",
    "{context_faq}\n",
    "\"\"\"\n",
    "\n",
    "prompt = create_prompt(prompt_str)\n",
    "\n",
    "retrieval = RunnableParallel(\n",
    "    {\n",
    "        \"context_customizations\": RunnableLambda(itemgetter(\"input\")) | retriever_customizations, \n",
    "        \"context_faq\": RunnableLambda(itemgetter(\"input\")) | retriever_customizations,\n",
    "        'input': itemgetter(\"input\"),\n",
    "        'history': itemgetter(\"history\")\n",
    "    }\n",
    ")\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "chain = retrieval | prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 97cf57f4-39c5-4072-b810-f8cfe491ea82 not found for run 2756e292-35ca-4257-ae3b-ea90c41a671a. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, you can determine the size of the ring at home. The size ranges from 4 to 13, and the ring width ranges from 1mm to 8mm. You can measure your finger size using a ring sizer tool or by using a printable ring size chart available online.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"input\": \"Is there a way to determine the size of the ring for me at home?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Router (input classification) chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Topic(str, Enum):\n",
    "    CUSTOMIZATION = 'customization'\n",
    "    RING = 'ring'\n",
    "    REQUEST = 'request'\n",
    "    FAQ = 'faq'\n",
    "\n",
    "#- If the user is admitting that the request to support is finalized (message \"Confirm\") classify as \"request\".\n",
    "\n",
    "router_prompt_str = \"\"\"\n",
    "Given the input and the conversation history classify:\n",
    "\n",
    "- If the user would like to customize or order a ring (\"I would like to order a ring\", \"I would like to customize a ring\" etc.), or being in the process of customizing giving to you a selected options from the customization context classify as \"customization\".\n",
    "- If correctness of the customizations is being confirmed (message \"Correct\") classify as \"ring\".\n",
    "- If the user expresses frustration, issues, or needs help beyond FAQ answers (e.g., \"I can't find my order,\" \"I need help with my account\") or would like to make a direct request or to reach out for a support team OR you just received message \"Confirm\" classify as \"request\".\n",
    "- If the user asks questions covered in the FAQ classify as \"faq\".\n",
    "\n",
    "Notice: \n",
    "Do not answer the question or make up the answer or question, only return as simple as possible, eithter 'customization', 'ring', 'request' or 'faq' as string without any instruction text, reasoning text, headlines, leading-text or other additional information.\n",
    "\n",
    "Customizations Context: \n",
    "{context_customizations}\n",
    "\n",
    "Format instructions:\n",
    "{format_instructions}\n",
    "Answer:\n",
    "\"\"\"\n",
    "router_prompt_str = router_prompt_str.replace(\n",
    "    '{format_instructions}', EnumOutputParser(enum=Topic).get_format_instructions()\n",
    ")\n",
    "router_prompt = create_prompt(router_prompt_str, include_history=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval = RunnableParallel(\n",
    "    {\n",
    "        \"context_customizations\": RunnableLambda(itemgetter(\"input\")) | retriever_customizations, \n",
    "        \"context_faq\": RunnableLambda(itemgetter(\"input\")) | retriever_faq,\n",
    "        'input': itemgetter(\"input\"),\n",
    "        'history': itemgetter(\"history\")\n",
    "    }\n",
    ")\n",
    "\n",
    "router_parser = StrOutputParser()\n",
    "\n",
    "router_chain = {\n",
    "    \"context_customizations\": itemgetter('context_customizations'), \n",
    "    \"context_faq\": itemgetter(\"context_faq\"),\n",
    "    'input': itemgetter(\"input\"),\n",
    "    'history': itemgetter(\"history\"),\n",
    "    'topic': router_prompt | llm | router_parser\n",
    "}\n",
    "\n",
    "chain = retrieval | router_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run e2ea5fbd-6a91-4cc3-bb92-1afbb55bd8a0 not found for run 4aa679a8-1399-488a-b394-3f60abc320e8. Treating as a root run.\n",
      "Error in RootListenersTracer.on_chain_end callback: KeyError('output')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_customizations': [Document(page_content='#### Size\\nFrom 4 to 13\\n\\n#### Ring Width\\nFrom 1mm to 8mm\\n\\n#### Engraving\\nUp to 20 characters or empty', metadata={'source': 'data/customization.md'}),\n",
       "  Document(page_content='#### Material\\n- Yellow Gold\\n- White Gold\\n- Platinum\\n- Sterling Silver\\n- Titanium\\n\\n#### Style\\n-\\tClassic\\n-\\tModern\\n-\\tVintage\\n-\\tBohemian\\n\\n#### Surface\\n-\\tPolished\\n-\\tMatte\\n-\\tHammered\\n-\\tBrushed', metadata={'source': 'data/customization.md'})],\n",
       " 'context_faq': [Document(page_content='**Q:** Can I get assistance with my design?\\n**A:** Yes, our design team is available to help you create the perfect ring.', metadata={'source': 'data/FAQ.md'}),\n",
       "  Document(page_content='**Q:** What materials are the rings made from?\\n**A:** Our rings are available in gold, silver, platinum, and titanium.', metadata={'source': 'data/FAQ.md'})],\n",
       " 'input': 'I would like to have a ring: gold, classic, polished, size 5, 2mm, no engraving. Complete',\n",
       " 'history': [],\n",
       " 'topic': 'ring'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"input\": \"I would like to have a ring: gold, classic, polished, size 5, 2mm, no engraving. Complete\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branch chain for different tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_customization_prompt_str = \"\"\"\n",
    "Your task it to guide the user through the process of a ring customization. Firstly, you give all the possible customizations and their options to the customer. Ask the customer to choose all the customizations from the possible options given in the context. Make sure user fills in all of the possible customizations. Do not allow user to select options on customizations that were not specified in the context. Check if user selects customizations that are not valid and in that case correct them. If user forgets to specify some customizations remind the user to select one of available choises. After all the customizations are collected, show all the customizations and options selected by user once again and ask to confirm the customizations by typing \"Correct\". If something goes wrong or your struggle to answer customer questions or fullfill customer's request, politely explain that you cannot anser that question and propose to the customer that the question can be passed to the support team. Ask to type \"Confirm\" in that case.\n",
    "\n",
    "Context:\n",
    "{context_customizations}\n",
    "\"\"\"\n",
    "ring_customization_prompt = create_prompt(ring_customization_prompt_str)\n",
    "ring_customization_chain = ring_customization_prompt | llm | output_parser\n",
    "\n",
    "ring_customization_output_prompt_str = \"\"\"\n",
    "Your task is to collect the user customizations from the current conversation and format it appropriately.\n",
    "\n",
    "Output format is JSON with fields:\n",
    "material\n",
    "style\n",
    "surface\n",
    "size\n",
    "ring_width\n",
    "engraving\n",
    "\n",
    "Notice:\n",
    "Do not add other fields.\n",
    "\"\"\"\n",
    "# ring_customization_output_parser = PydanticOutputParser(pydantic_object=Ring)\n",
    "ring_customization_output_prompt = create_prompt(ring_customization_output_prompt_str)\n",
    "ring_customization_output_chain = (ring_customization_output_prompt \n",
    "                                   | llm.bind(response_format={\"type\": \"json_object\"}) \n",
    "                                   | JsonOutputParser(pydantic_object=Ring)\n",
    "                                   )\n",
    "\n",
    "# support_prompt_str = \"\"\"\n",
    "# Your task is to collect information, summarize and extract key details on the request from user based on the current conversation. After the user told what is the request, repeat it for user and ask for the verification on correctness. Ask to type \"Confirm\" in that case.\n",
    "# \"\"\"\n",
    "# support_prompt = create_prompt(support_prompt_str)\n",
    "# support_chain = support_prompt | llm | output_parser\n",
    "\n",
    "support_output_prompt_str = \"\"\"\n",
    "Your task is to collect the last user request from the current conversation and format it appropriately.\n",
    "\n",
    "Output format is JSON with fields:\n",
    "customer_message\n",
    "conversation_summary\n",
    "key_details\n",
    "\n",
    "Notice:\n",
    "Do not add other fields.\n",
    "\"\"\"\n",
    "support_output_prompt = create_prompt(support_output_prompt_str)\n",
    "support_output_chain = (support_output_prompt \n",
    "                        | llm.bind(response_format={\"type\": \"json_object\"}) \n",
    "                        | JsonOutputParser(pydantic_object=SupportRequest)\n",
    "                        )\n",
    "\n",
    "faq_prompt_str = \"\"\"\n",
    "Your task is to answer questions based on context. If question is not covered in the context, explain is not covered in our FAQ and propose to the customer that the question can be passed to the support team. Ask to type \"Confirm\" in that case.\n",
    "\n",
    "Customizations Context: {context_customizations}\n",
    "FAQ Context: {context_faq}\n",
    "\"\"\"\n",
    "faq_prompt = create_prompt(faq_prompt_str)\n",
    "faq_chain = faq_prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    print(info['topic'])\n",
    "    if \"customization\" in info[\"topic\"].lower():\n",
    "        return ring_customization_chain\n",
    "    elif \"ring\" in info[\"topic\"].lower():\n",
    "        return ring_customization_output_chain.with_types(output_type=Ring)\n",
    "    elif \"request\" in info[\"topic\"].lower():\n",
    "        return support_output_chain.with_types(output_type=SupportRequest)\n",
    "    else:\n",
    "        return faq_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = retrieval | router_chain | RunnableLambda(route)\n",
    "\n",
    "store = {}\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 663c8d8b-a50c-44fd-b9a3-6eb66d93b73b not found for run 7c66d42d-9848-4518-9a8c-89354a278c94. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human: Hello, I would like to customize a ring\n",
      "customization\n",
      "\n",
      "AI: Great! I can help you with that. Let's start by selecting the customization options for your ring. Here are the possible customizations:\n",
      "\n",
      "1. Size (From 4 to 13)\n",
      "2. Ring Width (From 1mm to 8mm)\n",
      "3. Engraving (Up to 20 characters or empty)\n",
      "4. Material (Yellow Gold, White Gold, Platinum, Sterling Silver, Titanium)\n",
      "5. Style (Classic, Modern, Vintage, Bohemian)\n",
      "6. Surface (Polished, Matte, Hammered, Brushed)\n",
      "\n",
      "Please choose your preferences for each customization option. Let's start with the first one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run b8733b01-b8e1-4fb7-82a5-04fa10e7f20b not found for run ba891f8e-d4d5-4a34-8b94-65a72700fd4a. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human: size 5, 1mm, no engraving, classic, matte\n",
      "customization\n",
      "\n",
      "AI: Great choices! Let's review your selections:\n",
      "- Size: 5\n",
      "- Ring Width: 1mm\n",
      "- Engraving: None\n",
      "- Style: Classic\n",
      "- Surface: Matte\n",
      "\n",
      "Please confirm if these are correct by typing \"Correct\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run f7945185-aae7-49ec-bbfb-369de0e38ed2 not found for run c0a9e9e6-5160-4250-8631-bfd31141deb3. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human: Correct\n",
      "ring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: KeyError('output')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: {'material': 'Not specified', 'style': 'Classic', 'surface': 'Matte', 'size': '5', 'ring_width': '1mm', 'engraving': 'None'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 56ddc40d-8935-4cf0-b514-4a487203058e not found for run 2c797552-4564-4105-bdd4-2b44fa2d13bf. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human: I would like to make a direct request: I forgot to include material (gold) in my recent customization\n",
      "request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: KeyError('output')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: {'customer_message': 'I would like to make a direct request: I forgot to include material (gold) in my recent customization', 'conversation_summary': 'Customer wants to include gold as the material in their recent ring customization.', 'key_details': {'material': 'Gold'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 9fe08451-6f9d-4b7d-83e3-8df8fc20a33d not found for run 687cde55-42d6-4e3c-9949-409a62d837c6. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human: Also, I wanted to know how to determine my size?\n",
      "faq\n",
      "\n",
      "AI: You can determine your ring size by using a ring sizer tool or by visiting a local jeweler to get your finger measured. If you're unsure about your size, you can refer to our size chart that provides American sizes from 4 to 13. Would you like me to provide more details on how to measure your ring size accurately?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 33a0e6a3-622a-42b2-8601-1d060f1a46b3 not found for run f2c241a1-5c57-4602-a916-cfcab27ee67a. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human: yes, please\n",
      "request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: KeyError('output')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: {'customer_message': 'I would like to customize a ring', 'conversation_summary': 'Customer wants to customize a ring with the following specifications: Size 5, Ring Width 1mm, No Engraving, Classic Style, Matte Surface. Customer also wants to know how to determine their ring size.', 'key_details': {'customization_options': {'Size': '5', 'Ring Width': '1mm', 'Engraving': 'None', 'Style': 'Classic', 'Surface': 'Matte'}, 'additional_request': 'Customer wants to know how to determine their ring size'}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m human_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m human_input \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     human_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mHuman:\u001b[39m\u001b[38;5;124m'\u001b[39m, human_input)\n\u001b[1;32m      6\u001b[0m ai_output \u001b[38;5;241m=\u001b[39m with_message_history\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m      7\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: human_input},\n\u001b[1;32m      8\u001b[0m     config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabc123\u001b[39m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ring-customizer/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ring-customizer/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    human_input = ''\n",
    "    while human_input == '':\n",
    "        human_input = input()\n",
    "    print('\\nHuman:', human_input)\n",
    "    ai_output = with_message_history.invoke(\n",
    "        {\"input\": human_input},\n",
    "        config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    "    )\n",
    "    print('\\nAI:', ai_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ring-customizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
